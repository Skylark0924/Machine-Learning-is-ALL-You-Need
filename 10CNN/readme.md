# Convolutional Neural Network
> Image Classification & Feature Extraction

## Principle
æœ¬åº“ä½¿ç”¨CIFAR10æ•°æ®é›†ï¼Œåªå®ç°äº†ç®€å•çš„CNNï¼Œå…¶ä½™é«˜çº§variantsè¯¦è§[pytorch-cifar](https://github.com/kuangliu/pytorch-cifar)(åŒ…å«VGG, Resnet, MobileNet, Googlenet, EfficientNet, Densenet, Shufflenet, Regnet, DPN)

å› ä¸º CNN å¼€å§‹å°±ä¸å†æ˜¯ sklearn çš„èŒƒå›´äº†ï¼Œæˆ‘å¯»æ€ç€åŠ ä¸€ä¸ªtensorflowçš„åŸç”Ÿç‰ˆæœ¬å§ã€‚Guess what? ç›¸æ¯”äºkeraså’Œpytorchï¼Œè¿™ç®€ç›´æ˜¯åœ°ç‹±çº§éš¾åº¦ï¼ğŸ™‚ğŸ™‚ğŸ™‚ğŸ™‚ğŸ™‚ğŸ™‚ğŸ™‚ğŸ™‚
æ‹¥æœ‰keraså’ŒpytorchçœŸæ˜¯ä»¶å¹¸è¿çš„äº‹ã€‚æˆ‘ç”šè‡³è§‰å¾—æ¯”æˆ‘è‡ªå·±å†™çš„éƒ½éº»çƒ¦ï¼Œå¤§å®¶è‡ªå·±å¯¹æ¯”ä¸€ä¸‹å„ä¸ªç±»çš„ä»£ç é•¿åº¦å§ï¼Œéƒ½æ”¾åœ¨[`models.py`](models.py)é‡Œäº†ã€‚

- Skylark_CNN
- Keras_CNN
- Torch_CNN
- TF_CNN

Trust me! Do not use TF for beginning!

CNNçš„ä¸»ä½“å°±æ˜¯`å·ç§¯+æ± åŒ–+å…¨è¿æ¥`ä¸‰æ­¥ï¼Œself-implementç®€å•åœ°æ„å»ºäº†ä¸€å±‚å·ç§¯æ± åŒ–å…¨è¿æ¥ï¼Œå¦‚æœéœ€è¦æ›´å¤šå¯ä»¥åƒkeraså’Œpytorchä¸€æ ·åŠ å±‚ã€‚å®æµ‹mnistè®­ç»ƒé›†å¯ä»¥è¾¾åˆ°100%ï¼ŒCIFAR10æœ‰äº›å‹‰å¼ºemmmã€‚

æ³¨ï¼š- å…¨è¿æ¥è¿™é‡Œå†™çš„ä¸æ˜¯å¾ˆå¥½ï¼Œéœ€è¦æ”¹classï¼Œå¾…ä¿®æ”¹ï¼Œ
    - batchä¹Ÿæ²¡æœ‰åŠ å…¥ï¼Œç°åœ¨è¿˜æ˜¯batch=1ï¼ŒTODO
    - æ¬¢è¿contributeã€‚
```
        self.conv2d = Conv3x3(8)                # 32x32x1 -> 30x30x8
        self.pool = MaxPool2()                  # 30x30x8 -> 15x15x8
        self.softmax = Softmax(15 * 15 * 8, 10) # 15x15x8 -> 10
```

![](https://pic2.zhimg.com/v2-ae8a4d6f0ded77d731f179f361254db1_b.webp)

### Convolution
```
  def iterate_regions(self, image):
    '''
    Generates all possible 3x3 image regions using valid padding.
    - image is a 2d numpy array.
    '''
    h, w = image.shape

    for i in range(h - 2):
      for j in range(w - 2):
        im_region = image[i:(i + 3), j:(j + 3)]
        yield im_region, i, j

  def forward(self, input):
    '''
    Performs a forward pass of the conv layer using the given input.
    Returns a 3d numpy array with dimensions (h, w, num_filters).
    - input is a 2d numpy array
    '''
    self.last_input = input

    h, w = input.shape
    output = np.zeros((h - 2, w - 2, self.num_filters))

    for im_region, i, j in self.iterate_regions(input):
      output[i, j] = np.sum(im_region * self.filters, axis=(1, 2))

    return output
```
- è®¾è®¡ä¸€ä¸ªç”Ÿæˆå™¨ç”¨äºä»å›¾åƒä¸Šåˆ‡å‰²ä¸å·ç§¯æ ¸ç›¸åŒå¤§å°çš„å›¾åƒå—ï¼›
- å·ç§¯åçš„è¾“å‡ºå°ºå¯¸æ˜¯(h - 2, w - 2, self.num_filters)ï¼Œè¿™é‡Œæœªè€ƒè™‘è¡¥é›¶paddingæ“ä½œï¼Œæ‰€ä»¥ä¼šæœ‰è¾¹ç¼˜ç¼ºå¤±ï¼›
- å¯¹äºoutputçš„æ¯ä¸€ä¸ªzè½´ï¼Œæ˜¯ä¸€ä¸ªé•¿åº¦ä¸ºself.num_filters=8çš„æ•°ç»„ï¼Œ`np.sum(im_region * self.filters, axis=(1, 2))`å°† 3x3 çŸ©é˜µä¸8ä¸ª 3x3 çš„æ»¤æ³¢å™¨ä¹˜åœ¨ä¸€èµ·å¾—åˆ°ä¸€ä¸ª8x3x3çš„çŸ©é˜µï¼Œå†å¯¹ç¬¬äºŒã€ä¸‰ç»´æ±‚å’Œï¼Œå³å¾—é•¿åº¦ä¸º8çš„æ•°ç»„ã€‚

### Maxpool
```
  def iterate_regions(self, image):
    '''
    Generates non-overlapping 2x2 image regions to pool over.
    - image is a 2d numpy array
    '''
    h, w, _ = image.shape
    new_h = h // 2
    new_w = w // 2

    for i in range(new_h):
      for j in range(new_w):
        im_region = image[(i * 2):(i * 2 + 2), (j * 2):(j * 2 + 2)]
        yield im_region, i, j

  def forward(self, input):
    '''
    Performs a forward pass of the maxpool layer using the given input.
    Returns a 3d numpy array with dimensions (h / 2, w / 2, num_filters).
    - input is a 3d numpy array with dimensions (h, w, num_filters)
    '''
    self.last_input = input

    h, w, num_filters = input.shape
    output = np.zeros((h // 2, w // 2, num_filters))

    for im_region, i, j in self.iterate_regions(input):
      output[i, j] = np.amax(im_region, axis=(0, 1))

    return output
```
- è¿™é‡Œç”¨çš„æ˜¯2x2æœ€å¤§æ± åŒ–ï¼Œå› æ­¤è¦ä»ä¸Šä¸€æ­¥çš„è¾“å‡ºä¸­åˆ¶ä½œä¸€ä¸ªç”Ÿæˆå™¨æ¥ç”Ÿæˆæ‰€æœ‰2x2å¤§å°çš„ä¸‹å›¾åƒå—ï¼›
- 2x2æœ€å¤§æ± åŒ–åçš„è¾“å‡ºæ˜¯åŸé•¿å®½çš„ä¸€åŠï¼Œ(h // 2, w // 2, num_filters)ï¼›
- outputçš„æ¯ä¸€ä¸ªzå‘é‡æ˜¯è¿™ä¸ª2x2å›¾åƒå—ä¸­å€¼æœ€å¤§çš„é‚£ä¸€ä¸ªã€‚

### Softmax
```
  def forward(self, input):
    '''
    Performs a forward pass of the softmax layer using the given input.
    Returns a 1d numpy array containing the respective probability values.
    - input can be any array with any dimensions.
    '''
    self.last_input_shape = input.shape

    input = input.flatten()
    self.last_input = input

    input_len, nodes = self.weights.shape

    totals = np.dot(input, self.weights) + self.biases
    self.last_totals = totals

    exp = np.exp(totals)
    return exp / np.sum(exp, axis=0)
```
- è¿™é‡Œçš„softmaxåŒ…å«äº†å…¨è¿æ¥è¾“å‡ºå±‚ï¼›
- å…ˆå°†ä¸Šä¸€æ­¥çš„outputå±•å¹³`input = input.flatten()`ï¼›
- ç»è¿‡ä¸€å±‚å…¨è¿æ¥`totals = np.dot(input, self.weights) + self.biases`ï¼›
- softmaxæ¿€æ´»å‡½æ•°`exp = np.exp(totals); exp / np.sum(exp, axis=0)`ï¼›
- å¾—åˆ°å…¶å±äºå„ä¸ªç±»åˆ«çš„å¯èƒ½æ€§ï¼Œè¿™æ˜¯ä¸€ä¸ªé•¿åº¦ä¸º10çš„æ•°ç»„ï¼Œä¹‹åä¼šä½¿ç”¨argmaxä½œä¸ºæœ€ç»ˆé¢„æµ‹çš„ç±»åˆ«ã€‚

## Backpropagation
å½“ç„¶æ˜¯ å…¨è¿æ¥->æ± åŒ–->å·ç§¯
### Softmax backprop
```
  def backprop(self, d_L_d_out, learn_rate):
    '''
    Performs a backward pass of the softmax layer.
    Returns the loss gradient for this layer's inputs.
    - d_L_d_out is the loss gradient for this layer's outputs.
    - learn_rate is a float.
    '''
    # We know only 1 element of d_L_d_out will be nonzero
    for i, gradient in enumerate(d_L_d_out):
      if gradient == 0:
        continue

      # e^totals
      t_exp = np.exp(self.last_totals)
      # Sum of all e^totals
      S = np.sum(t_exp)
      # Gradients of out[i] against totals
      d_out_d_t = -t_exp[i] * t_exp / (S ** 2)
      d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)

      # Gradients of totals against weights/biases/input
      d_t_d_w = self.last_input
      d_t_d_b = 1
      d_t_d_inputs = self.weights

      # Gradients of loss against totals
      d_L_d_t = gradient * d_out_d_t

      # Gradients of loss against weights/biases/input
      d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]
      d_L_d_b = d_L_d_t * d_t_d_b
      d_L_d_inputs = d_t_d_inputs @ d_L_d_t

      # Update weights / biases
      self.weights -= learn_rate * d_L_d_w
      self.biases -= learn_rate * d_L_d_b

      return d_L_d_inputs.reshape(self.last_input_shape)
```
å…¨è¿æ¥çš„åå‘ä¼ æ’­æˆ‘ä»¬åœ¨ä¸Šä¸€ç« NNå·²ç»ç ”ç©¶è¿‡äº†ï¼Œè¿™é‡Œå¤§å®¶çœ‹çœ‹ä»£ç å°±ç†Ÿæ‚‰äº†ã€‚

### Maxpool backprop
```
  def backprop(self, d_L_d_out):
    '''
    Performs a backward pass of the maxpool layer.
    Returns the loss gradient for this layer's inputs.
    - d_L_d_out is the loss gradient for this layer's outputs.
    '''
    d_L_d_input = np.zeros(self.last_input.shape)

    for im_region, i, j in self.iterate_regions(self.last_input):
      h, w, f = im_region.shape
      amax = np.amax(im_region, axis=(0, 1))

      for i2 in range(h):
        for j2 in range(w):
          for f2 in range(f):
            # If this pixel was the max value, copy the gradient to it.
            if im_region[i2, j2, f2] == amax[f2]:
              d_L_d_input[i * 2 + i2, j * 2 + j2, f2] = d_L_d_out[i, j, f2]

    return d_L_d_input
```
åˆ©ç”¨self.last_inputæ¥æ‰¾å‡ºæœ€å¤§å€¼çš„ä½ç½®ï¼Œè¯·å°†å…¶è¿˜åŸåˆ°æ± åŒ–å‰çš„å°ºå¯¸ã€‚

![](https://img-blog.csdn.net/20170615211413093?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjExOTAwODE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

### Conv backprop
```
  def backprop(self, d_L_d_out, learn_rate):
    '''
    Performs a backward pass of the conv layer.
    - d_L_d_out is the loss gradient for this layer's outputs.
    - learn_rate is a float.
    '''
    d_L_d_filters = np.zeros(self.filters.shape)

    for im_region, i, j in self.iterate_regions(self.last_input):
      for f in range(self.num_filters):
        d_L_d_filters[f] += d_L_d_out[i, j, f] * im_region

    # Update filters
    self.filters -= learn_rate * d_L_d_filters

    # We aren't returning anything here since we use Conv3x3 as the first layer in our CNN.
    # Otherwise, we'd need to return the loss gradient for this layer's inputs, just like every
    # other layer in our CNN.
    return None
```
**å·ç§¯å‰å‘ä¼ æ’­**:
![](https://miro.medium.com/max/2000/1*wqZ0Q4mBaHKjqWx45GPIow.gif)

![](https://miro.medium.com/max/1262/1*8dwVouGJfSW5JU5hsJfvfw.png)

![](https://miro.medium.com/max/592/1*KrPwm8IVDzT4XHobJlK50Q.png)

**å·ç§¯åå‘ä¼ æ’­**ï¼š

è¿™é‡Œç”¨ $\partial h_{ij}$ ä»£è¡¨ $\frac{\partial L}{\partial h_{ij}}$ï¼Œç”¨ $\partial w_{ij}$ ä»£è¡¨ $\frac{\partial L}{\partial w_{ij}}$

![](https://miro.medium.com/max/2000/1*CkzOyjui3ymVqF54BR6AOQ.gif)

![](https://miro.medium.com/max/778/1*VruqyvXfFMrFCa3E9U6Eog.png)

- `self.last_input`å°±æ˜¯X
- `d_L_d_out`å°±æ˜¯$\frac{\partial L}{\partial h_{ij}}$
- `d_L_d_filters[f] += d_L_d_out[i, j, f] * im_region`å°±æ˜¯ç¬¬fä¸ªæ»¤æ³¢å™¨çš„3x3çš„ $\partial w$ã€‚ 

## Reference
1. [Forward And Backpropagation in Convolutional Neural Network](https://medium.com/@2017csm1006/forward-and-backpropagation-in-convolutional-neural-network-4dfa96d7b37e)
2. [Back Propagation in Convolutional Neural Networks â€” Intuition and Code](https://becominghuman.ai/back-propagation-in-convolutional-neural-networks-intuition-and-code-714ef1c38199)
3. [æ± åŒ–å±‚ï¼ˆpoolingï¼‰çš„åå‘ä¼ æ’­æ˜¯æ€ä¹ˆå®ç°çš„](https://blog.csdn.net/Jason_yyz/article/details/80003271)
4. [ä½¿ç”¨tensorflowæ„å»ºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰](https://zhuanlan.zhihu.com/p/30911463)